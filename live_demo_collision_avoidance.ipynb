{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "MOTOR = 0.35\n",
    "TRUN = 0.3\n",
    "\n",
    "# Alexnet\n",
    "PATH = '../models/AlexNet_S233M_W57.01M.pth'\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "# # MobileNetV2\n",
    "# PATH = '../models/MobileNetV2_S 13.6M_W2.23M.pth'\n",
    "# model = torchvision.models.mobilenet_v2(pretrained=False)\n",
    "# model.classifier[1] = torch.nn.Linear(in_features=1280, out_features=2, bias=True)\n",
    "\n",
    "# # RestNet18\n",
    "# PATH = '../models/ResNet18_S44.7M _W11.18M.pth'\n",
    "# model = torchvision.models.resnet18(pretrained=False)\n",
    "# model.fc = torch.nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "\n",
    "# # squeezenet\n",
    "# PATH = '../models/SqueezeNet_S 4.79M_W0.74M.pth'\n",
    "# model = torchvision.models.squeezenet1_0(pretrained=False)\n",
    "# model.classifier[1] = torch.nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: 224.0 224.0 FPS: 20.0\n",
      "Buffer: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd4c501a361438da8c4c6a20c1fcb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from jetbot import Robot\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from cameraX import CameraX\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "pre_direction = True # True is Left, Flase Right\n",
    "pre_state = False # True Blocked, False Free\n",
    "def update(change):\n",
    "    global blocked_slider, robot\n",
    "    global pre_direction, pre_state\n",
    "    start = time.time()\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    blocked_slider.value = prob_blocked\n",
    "    \n",
    "    if prob_blocked < 0.5:\n",
    "        robot.forward(MOTOR)\n",
    "        if pre_state == True: # Blocked\n",
    "            pre_direction = False if pre_direction else True # 反轉方向\n",
    "        pre_state = False # Free\n",
    "    else:\n",
    "        if pre_direction:\n",
    "            robot.left(TRUN)\n",
    "        else:\n",
    "            robot.right(TRUN + 0.1)\n",
    "        pre_state = True # Blocked\n",
    "    time.sleep(0.001)\n",
    "#     print('pre_direction:', pre_direction)\n",
    "    \n",
    "    # 計算FPS\n",
    "#     fps = 1 / (time.time() - start)\n",
    "#     cv2.putText(image, 'FPS: {:.0f}'.format(fps), (10, 210), cv2.FONT_HERSHEY_TRIPLEX, 1, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "#     print('\\rFPS: {:.0f}'.format(fps), end='')\n",
    "    \n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "# camera = Camera.instance(width=224, height=224, fps=20)\n",
    "cap = None\n",
    "camera = CameraX(fps=20)\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "display(widgets.HBox([image, blocked_slider]))\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(update, names='value')\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "robot.stop()\n",
    "\n",
    "camera_link.unlink()  # don't stream to browser (will still run camera)\n",
    "camera_link.link()  # stream to browser (wont run camera)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
